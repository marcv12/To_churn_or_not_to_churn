# Customer Churn with Python and Streamlit

Through this project, you will be able to predict whether customers in your bank will churn (leave) or not. I have also provided a website that implements this automatically, where all you have to do is upload a file.    
  

## Description
"To Churn or Not To Churn" is a data analysis project aimed at predicting customer churn using machine learning models. The primary models we've decided to use for this task are Random Forest (RF) and K-Nearest Neighbors (KNN). This project takes you through different stages of machine learning pipeline, from data exploration to model creation, optimization, and interpretation of final results.

## Installation
The project is written in Python 3. We recommend using a virtual environment to run the code. You can install the required packages using pip and the provided `requirements.txt` file:

```
pip install -r requirements.txt
```

The main libraries used in this project are:

- Pandas
- Numpy
- Scikit-Learn
- Matplotlib
- Seaborn
- Streamlit

## Project Motivation
In the business landscape, understanding and predicting customer churn is a key strategy for maintaining a healthy and profitable customer base. Our aim with this project is to create and optimize machine learning models that effectively predict customer churn. We are motivated by the potential impact of our work in assisting companies to understand their customers better and ultimately maintain customer loyalty.

## File Description
The repository contains the following key files:

- `main.py`: The main Python script where the data analysis is performed.
- `website.py`: A script to launch the web application.
- `requirements.txt`: Contains the necessary Python libraries required to run the project.
- `churn.csv`: The original dataset used in the project.
- `README.md`: The file you are currently reading.

## How to Interact with this Project

The main project code is located in **proj.py** and the code for the website in **website.py**  

For more information, I will provide **2 links**: one contains the report for the project (**fun and easy to follow!**) and the other a video where you will be able to see how the website works and how wonderfully well it works!  

I really hope you enjoy this project as much as I did doing it, and if you have any comments, I would be glad to respond!  

Links:  
[Report](https://drive.google.com/file/d/150EFKqmXmt2db7k8Qlv5PK74S-9IhOcJ/view?usp=sharing)  
[Website video demo](https://drive.google.com/file/d/1ZaXhpbdfDlXAtDvNhMxtr8kZZ_AcFPcG/view?usp=drivesdk)  

After installing the required packages, you can interact with this project in two main ways:

1. Run `main.py` to see the data analysis, model creation, and optimization process.
2. Launch the web application using `website.py` and interact with the final optimized model. You can do this by running `streamlit run website.py` in your terminal.

## Licensing
This project is licensed under the Apache License 2.0 - see the LICENSE file for more details.

## Acknowledgements
We would like to express our deepest gratitude to our professors and mentors who guided us throughout the project. We also acknowledge OpenAI's GPT-4 model for assisting in generating the text and insights for this README file. We appreciate the creators of the dataset and everyone else who contributed to making this project a success.
